{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLh0OhyNLThU"
      },
      "source": [
        "# Output the Association rule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r31TDxrLQcZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('./transactions.csv')\n",
        "\n",
        "# Preprocess data\n",
        "transactions = df['items'].apply(lambda x: x.split(', ')).tolist()\n",
        "encoder = TransactionEncoder()\n",
        "onehot = encoder.fit(transactions).transform(transactions)\n",
        "onehot_df = pd.DataFrame(onehot, columns=encoder.columns_)\n",
        "\n",
        "# Apply FP-Growth algorithm\n",
        "# Generate frequent itemsets with a lower support threshold\n",
        "min_support = 0.05  # Adjust this threshold based on your needs\n",
        "frequent_itemsets = fpgrowth(onehot_df, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Display frequent itemsets\n",
        "print(frequent_itemsets)\n",
        "\n",
        "# Generate association rules\n",
        "num_itemsets = len(frequent_itemsets)\n",
        "# Generate association rules with a lower confidence threshold\n",
        "rules = association_rules(frequent_itemsets, num_itemsets=num_itemsets, metric=\"confidence\", min_threshold=0.3)  # Adjust as needed\n",
        "\n",
        "# Display results\n",
        "print(\"Association Rules:\")\n",
        "print(rules)\n",
        "\n",
        "# Save frequent itemsets and association rules to CSV files\n",
        "#frequent_itemsets.to_csv('frequent_itemsets.csv', index=False)\n",
        "rules.to_csv('fpgrowth_association_rules.csv', index=False)\n",
        "\n",
        "print(\"Frequent itemsets and association rules have been saved to 'frequent_itemsets.csv' and 'association_rules.csv'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFJrMpomLXKD"
      },
      "source": [
        "# Association Rule Score Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_01yLdIHLf3g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def find_suitable_foods(food_types):\n",
        "    \"\"\"Find suitable food types based on the input list of food types.\"\"\"\n",
        "    global confidence_dishes_df\n",
        "\n",
        "    # Load the association rules from CSV\n",
        "    #rules_df = pd.read_csv(\"./apriori_association_rules.csv\")\n",
        "    rules_df = pd.read_csv(\"./fpgrowth_association_rules.csv\")\n",
        "\n",
        "    # Filter rules where any of the input food types are in the antecedents\n",
        "    suitable_rules = rules_df[rules_df['antecedents'].apply(lambda x: any(food in eval(x) for food in food_types))]\n",
        "\n",
        "    # Prepare output as a list of tuples (food, score)\n",
        "    suitable_foods = []\n",
        "    for index, row in suitable_rules.iterrows():\n",
        "        for consequent in eval(row['consequents']):\n",
        "            # Append the consequent and its confidence score\n",
        "            suitable_foods.append((consequent, row['confidence']))\n",
        "\n",
        "    confidence_dishes_df = pd.DataFrame(suitable_foods, columns=['Type', 'Score'])\n",
        "    # Sort by 'Combined_Score' in descending order\n",
        "    confidence_dishes_df = confidence_dishes_df.sort_values(by='Score', ascending=False)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Input food types\n",
        "    input_foods = [\"Sandwich\"]  # Change this to any list of food types you want to check\n",
        "    # Find suitable foods\n",
        "    find_suitable_foods(input_foods)\n",
        "    print(confidence_dishes_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZdZJIgYLc-j"
      },
      "source": [
        "# Recommender System Score Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV27z4BnLmH2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def recommend_dish(prep_time, cook_time):\n",
        "    global recommend_df\n",
        "\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv('./data_use_to_test_the_recommender_system/indian_food.csv')\n",
        "\n",
        "    # Fill any NaNs with zeros\n",
        "    df['prep_time'] = df['prep_time'].fillna(0)\n",
        "    df['cook_time'] = df['cook_time'].fillna(0)\n",
        "\n",
        "    # Prepare the feature matrix for prep_time and cook_time\n",
        "    features = df[['prep_time', 'cook_time']]\n",
        "    # Normalize the features\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(features)\n",
        "    # Create an input array for the provided times\n",
        "    input_times = [[prep_time, cook_time]]\n",
        "\n",
        "    # Scale the input times using the same scaler\n",
        "    scaled_input = scaler.transform(input_times)\n",
        "\n",
        "    # Compute the similarity scores using cosine similarity\n",
        "    sim_scores = cosine_similarity(scaled_input, scaled_features)\n",
        "\n",
        "    # Get indices of all dishes\n",
        "    sim_scores = sim_scores.flatten()\n",
        "\n",
        "    # Create a DataFrame for recommendations with scores\n",
        "    recommend_df = pd.DataFrame({\n",
        "        'Dish': df['name'],\n",
        "        'Type': df['type'],\n",
        "        'Score': sim_scores\n",
        "    })\n",
        "\n",
        "    # Sort by score in descending order and get top 5 recommendations\n",
        "    recommend_df = recommend_df.sort_values(by='Score', ascending=False)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prep_time_input = 20\n",
        "cook_time_input = 30\n",
        "\n",
        "recommend_dish(prep_time_input, cook_time_input)\n",
        "print(recommend_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbKVxHNLLnPs"
      },
      "source": [
        "# Final Score and Recommend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkNMpuD2LrgM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def combined_score(prep_time_input, cook_time_input, food_type):\n",
        "    global combined_df\n",
        "\n",
        "    Recommander_Weight = 1.0 # Weight of Content-base Recommander\n",
        "    Association_Weight = 1.0 # Weight of Association Rule\n",
        "\n",
        "    find_suitable_foods(food_type)\n",
        "    # find_similar_dishes(prep_time_input, cook_time_input)\n",
        "    recommend_dish(prep_time_input, cook_time_input)\n",
        "\n",
        "    # Merge the dataframes on the 'Type' column\n",
        "    merged_df = recommend_df.merge(confidence_dishes_df, on='Type', how='left')\n",
        "\n",
        "    # Add the scores from the two dataframes\n",
        "    combined_df = merged_df[['Dish', 'Type', 'Score_x', 'Score_y']].rename(columns={'Score_x': 'Recommander_Score', 'Score_y': 'Confidence_Score'})\n",
        "    combined_df['Combined_Score'] = (combined_df['Recommander_Score'] * Recommander_Weight) + (combined_df['Confidence_Score'] * Association_Weight)\n",
        "\n",
        "    # Drop rows with NaN values in 'Combined_Score'\n",
        "    combined_df = combined_df.dropna()\n",
        "\n",
        "    # Sort by 'Combined_Score' in descending order\n",
        "    sorted_combined_df = combined_df.sort_values(by='Combined_Score', ascending=False)\n",
        "\n",
        "    # Display the sorted combined dataframe\n",
        "    print(sorted_combined_df)\n",
        "\n",
        "prep_time_input = 10\n",
        "cook_time_input = 20\n",
        "food_type_input = [\"Meat\",\"Salad\"]\n",
        "combined_score(prep_time_input, cook_time_input, food_type_input)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
